# -*- coding: utf-8 -*-
"""CSE258-HW1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MihSdy2qQo0eQLw0gHa2D09BJv4Jod6F
"""

import json
from matplotlib import pyplot as plt
from collections import defaultdict
from sklearn import linear_model
import numpy as np
import random
import gzip
import math
# !pip install urllib
# from urllib import urlopen

def assertFloat(x): # Checks that an answer is a float
    assert type(float(x)) == float

def assertFloatList(items, N):
    assert len(items) == N
    assert [type(float(x)) for x in items] == [float]*N

"""#Regression

## Q1
"""

f = gzip.open("young_adult_10000.json.gz")
dataset = []
for l in f:
    dataset.append(json.loads(l))

dataset[0]

print(dataset[i]['review_text'].count('!') for i in range(10))

def feature(datum):
  feat = [1]
  #feat.append(datum['user/ageInSeconds'])
  feat.append(datum['review_text'].count('!'))
  return feat

# tmpArrExcl = []
# tmpArrExcl = [[1]]*len(dataset)
# for i in range(len(dataset)):
#   tmpArrExcl[i].append(dataset[i]['review_text'].count('!'))
tmpArrExcl = [feature(d) for d in dataset]

tmpArrExcl[:10]

ratings = []
for i in range(len(dataset)):
  ratings.append(dataset[i]["rating"])

ratings[:10]

# tmpArrExcl = np.array(tmpArrExcl)
# X = tmpArrExcl.reshape(-1,1)
# X[:10]

X = tmpArrExcl

ratings = np.array(ratings)
y = ratings.reshape(-1,1)
y[:10]

theta,residuals,rank,s = numpy.linalg.lstsq(X, y)

print(theta)

y_pred = np.dot(X, theta)

MSE = ((y - y_pred)**2).mean()
print(MSE)

"""## Q2"""

def feature(datum):
  feat = [1]
  feat.append(len(datum['review_text']))
  
  feat.append(datum['review_text'].count('!'))
  return feat

X = [feature(d) for d in dataset]

X[:10]

theta,residuals,rank,s = numpy.linalg.lstsq(X, y)

theta

y_pred = np.dot(X, theta)

MSE = ((y - y_pred)**2).mean()
print(MSE)

"""## Q3"""

def feature(datum,i):
  feat = [1]
  for j in range(1,i+1):
    feat.append((datum['review_text'].count('!'))**j)
  return feat

for i in range(1,6):
  X = [feature(d,i) for d in dataset]
  # print(X[:10])
  theta,residuals,rank,s = numpy.linalg.lstsq(X, y)
  y_pred = np.dot(X, theta)
  MSE = ((y - y_pred)**2).mean()
  print("MSE",i,MSE)

X[:10]

type(dataset)

"""##Q4"""

d_train = dataset[:len(dataset)//2]
d_test = dataset[(len(dataset)//2)+1:]
y_train = y[:len(y)//2]
y_test = y[(len(y)//2)+1:]

for i in range(1,6):
  X_train = [feature(d,i) for d in d_train]
  X_test = [feature(d,i) for d in d_test]
  # print(X[:10])
  theta,residuals,rank,s = numpy.linalg.lstsq(X_train, y_train)
  y_pred = np.dot(X_test, theta)
  MSE = ((y_test - y_pred)**2).mean()
  print("MSE",i,MSE)

"""## Q5"""

import scipy.optimize

def MAE(theta0):
  # we will optimize the MAE function based on theta0 which with no other features is the final yPred.
  sumi = 0
  for i in range(len(y_test)):
    sumi += abs(theta0-y_test[i])
  sumi = sumi/len(y_test)
  return sumi

guess = [0]
ans = scipy.optimize.minimize(MAE,guess)
print(ans)

theta0 = 4.0
ans = MAE(theta0)

print(ans)

"""# Classification

## Q6
"""

from urllib.request import urlopen
def parseDataFromURL(fname):
  for l in urlopen(fname):
    yield eval(l)

data = list(parseDataFromURL("http://cseweb.ucsd.edu/classes/fa19/cse258-a/data/beer_50000.json"))

data[1000]

dataset = [d for d in data if 'user/gender' in d]

dataset[0]

len(dataset)

# checing of only male and female exist
c = 0
for i in range(len(dataset)):
  if(dataset[i]['user/gender'] == 'Male') or (dataset[i]['user/gender'] == 'Female'):
    c+=1
print(c)

"""### Hot encode"""

for i in range(len(dataset)):
  if(dataset[i]['user/gender'] == 'Male'):
    dataset[i]['user/gender'] = 0
  else:
    dataset[i]['user/gender'] = 1

dataset[21]

"""### Classification"""

from sklearn.linear_model import LogisticRegression

def feature(datum):
  feat = [1]
  feat.append(datum['review/text'].count('!'))
  return feat

X = [feature(d) for d in dataset]

X[:10]

def labell(datum):
  feat = []
  feat.append(datum['user/gender'])
  return feat

y = [labell(d)[0] for d in dataset]

y[:10]

classModel = LogisticRegression().fit(X,y)

y_pred = classModel.predict(X)

y_pred[:10]

Tp,Tn,Fp,Fn = 0,0,0,0
for i in range(len(y)):
  if y[i] == y_pred[i] == 1: # female
    Tp+=1
  elif y[i] == 1 and y_pred[i] == 0:
    Fn+=1
  elif y[i] == y_pred[i] == 0: # male
    Tn+=1
  else:
    Fp+=1

print(Tp,Tn,Fp,Fn)

from sklearn.metrics import balanced_accuracy_score

balanced_accuracy_score(y,y_pred)

BER = 1 - 0.5 * (Tp / (Tp + Fn) + Tn / (Tn + Fp))
print(BER)

"""## Q7"""

classModel = LogisticRegression(class_weight="balanced").fit(X,y)

y_pred = classModel.predict(X)

Tp,Tn,Fp,Fn = 0,0,0,0
for i in range(len(y)):
  if y[i] == y_pred[i] == 1: # female
    Tp+=1
  elif y[i] == 1 and y_pred[i] == 0:
    Fn+=1
  elif y[i] == y_pred[i] == 0: # male
    Tn+=1
  else:
    Fp+=1

print(Tp,Tn,Fp,Fn)

balanced_accuracy_score(y,y_pred)
# uploading old value cause this agains balances it, waste

BER = 1 - 0.5 * (Tp / (Tp + Fn) + Tn / (Tn + Fp))
print(BER)

"""### Q8"""

tmp = y_pred

k = [1, 10, 100, 1000, 10000]
sumi = 0
for i in k:
  sumi = 0
  for j in range(i):
    if y[j] == y_pred[j] == 1: # female
      sumi+=y_pred[j]
    elif y[j] == y_pred[j] == 0: # male
      sumi+=y_pred[j]
  sumi/=i
  print("precision@",i,sumi)

"""#### Precision@K using weights(confidence)"""

scores = classModel.decision_function(X)
scores = list(zip(scores, y))
scores.sort(reverse=True)
sortedScore = [i[1] for i in scores]
precisionlist = []
for i in k:
  print("precision@",i,sum(sortedScore[:i])/i)

# print(precisionlist)

